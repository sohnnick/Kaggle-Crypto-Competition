{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "import gresearch_crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gresearch_crypto.make_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv('../input/g-research-crypto-forecasting/train.csv', low_memory=False)\n",
    "df_test = pd.read_csv('../input/g-research-crypto-forecasting/supplemental_train.csv',\n",
    "                     low_memory=False).sample(20000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not null\n",
    "df_test = df_test[df_test['Target'].notnull()]\n",
    "df_all = df_all[df_all['Target'].notnull()]\n",
    "df_all = df_all[(df_all['VWAP'] != -np.inf) & (df_all['VWAP'] != np.inf)]\n",
    "df_all = df_all[df_all['VWAP'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique assets\n",
    "unique_assets = df_all['Asset_ID'].unique()\n",
    "unique_assets.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_reduced = []\n",
    "for i in tqdm(unique_assets):\n",
    "    asset_type = df_all[df_all['Asset_ID'] == i].sort_values('timestamp')\n",
    "    dfs_reduced.append(asset_type.sample(100000, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reduced = pd.concat(dfs_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(categories = 'auto')\n",
    "np_train = np.array(df_reduced['Asset_ID']).reshape(-1,1)\n",
    "np_test = np.array(df_test['Asset_ID']).reshape(-1,1)\n",
    "\n",
    "encoder.fit(np_train)\n",
    "asset_cols = list(encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform training set\n",
    "encoded_train = encoder.transform(np_train).toarray()\n",
    "df_encoded_train = pd.DataFrame(encoded_train, columns=asset_cols)\n",
    "\n",
    "# transform test set\n",
    "encoded_test = encoder.transform(np_test).toarray()\n",
    "df_encoded_test = pd.DataFrame(encoded_test, columns=asset_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['Open', 'Close', 'High', 'Low', 'Volume', 'VWAP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_reduced[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_transformed = pd.DataFrame(scaler.transform(df_reduced[feats]), columns = feats)\n",
    "df_test_transformed = pd.DataFrame(scaler.transform(df_test[feats]), columns = feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pro = pd.concat([df_encoded_train.reset_index(drop=True), \n",
    "                          df_train_transformed.reset_index(drop=True), \n",
    "                          df_reduced['Target'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "df_test_pro = pd.concat([df_encoded_test.reset_index(drop=True), \n",
    "                         df_test_transformed.reset_index(drop=True),\n",
    "                         df_test['Target'].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X and Y Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_train_pro[asset_cols + feats]\n",
    "y_train = df_train_pro['Target']\n",
    "\n",
    "x_test = df_test_pro[asset_cols + feats]\n",
    "y_test = df_test_pro['Target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgb.XGBRegressor(objective= \"reg:squarederror\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, _ = pearsonr(pred, y_test)\n",
    "print('Correlation Score:', corr)\n",
    "\n",
    "rmse = mean_squared_error(pred, y_test, squared=False)\n",
    "print('RMSE:', rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "#     print(test_df)\n",
    "    # one-hot encode\n",
    "    np_asset_submit = np.array(test_df['Asset_ID']).reshape(-1,1)\n",
    "    encoded_asset_encoded = encoder.transform(np_asset_submit).toarray()\n",
    "    df_asset_encoded = pd.DataFrame(encoded_asset_encoded, columns=asset_cols)\n",
    "    \n",
    "    # min-max scale\n",
    "    df_feats_transformed = pd.DataFrame(scaler.transform(test_df[feats]), columns = feats)\n",
    "    \n",
    "    # concat\n",
    "    input_row = pd.concat([df_asset_encoded.reset_index(drop=True), \n",
    "                          df_feats_transformed.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "#     print(input_row)\n",
    "    \n",
    "    sample_prediction_df['Target'] = xgb_reg.predict(input_row)\n",
    "    env.predict(sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
